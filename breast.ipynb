{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT94AfhUNFYr"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow.image as tfi\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D ,BatchNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet,preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#!pip install opendatasets\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import opendatasets as od\n",
        "\n",
        "from google.colab import files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IydJiSY788Mz",
        "outputId": "137f15a5-96bd-4de9-e442-0eddfab58b88"
      },
      "outputs": [],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrU5dMTFHEtd"
      },
      "outputs": [],
      "source": [
        "#Remove mask\n",
        "\n",
        "b=\"/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign\"\n",
        "m=\"/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant\"\n",
        "n=\"/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal\"\n",
        "for dir in os.listdir(n):\n",
        "  \n",
        "  p=os.path.join(n,dir)\n",
        "  isexist = os.path.exists(p)\n",
        "  if p.find(\"_mask\")>=0:\n",
        "    print(p)\n",
        "    print(isexist)\n",
        "    if isexist :\n",
        "      print(p)\n",
        "      os.remove(p)\n",
        "for dir in os.listdir(b):\n",
        "  \n",
        "  p=os.path.join(b,dir)\n",
        "  isexist = os.path.exists(p)\n",
        "  if p.find(\"_mask\")>=0:\n",
        "    print(p)\n",
        "    print(isexist)\n",
        "    if isexist :\n",
        "      print(p)\n",
        "      os.remove(p)\n",
        "for dir in os.listdir(m):\n",
        "  \n",
        "  p=os.path.join(m,dir)\n",
        "  isexist = os.path.exists(p)\n",
        "  if p.find(\"_mask\")>=0:\n",
        "    print(p)\n",
        "    print(isexist)\n",
        "    if isexist :\n",
        "      print(p)\n",
        "      os.remove(p)\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "yKM_LD1ONX3N",
        "outputId": "c2f6ace9-a4ad-45d4-96cd-43f8e01912b1"
      },
      "outputs": [],
      "source": [
        "\n",
        "image2 = cv2.imread('/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (10).png')\n",
        "heatmap1 = cv2.applyColorMap(image2, cv2.COLORMAP_JET)\n",
        "heatmap2 = cv2.cvtColor(heatmap1, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "cv2.GaussianBlur(image2)\n",
        "cv2_imshow(heatmap2)\n",
        "cv2_imshow(image2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIFjlax6NX8r"
      },
      "outputs": [],
      "source": [
        "#uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw4ZAfvMNYA3"
      },
      "outputs": [],
      "source": [
        "#count images according to classes \n",
        "pathTrain=\"/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT\"\n",
        "pathCV = \"/content/breast-ultrasound-images-dataset/test\"\n",
        "pathTest=\"/content/breast-ultrasound-images-dataset/cv\"\n",
        "img_height=224\n",
        "img_width=224\n",
        "batchSize = 32\n",
        "\n",
        "numberOfTrain = {}\n",
        "numberOfCV = {}\n",
        "numberOfTest={}\n",
        "\n",
        "images_train_data={}\n",
        "images_CV_data={}\n",
        "images_Test_data={}\n",
        "\n",
        "\n",
        "pathOfEachTrain=[]\n",
        "pathOfEachCV=[]\n",
        "pathOfEachtest=[]\n",
        "labels=[]\n",
        "n_images=0\n",
        "for dir in os.listdir(pathTrain):\n",
        "  images_train_data[dir]=os.listdir(os.path.join(pathTrain,dir))\n",
        "  pathOfEachTrain.append(os.path.join(pathTrain,dir))\n",
        "  numberOfTrain[dir] = len(os.listdir(os.path.join(pathTrain,dir)))\n",
        "  n_images+=len(os.listdir(os.path.join(pathTrain,dir)))\n",
        "for dir in os.listdir(pathCV):\n",
        "  images_CV_data[dir]=os.listdir(os.path.join(pathCV,dir))\n",
        "  pathOfEachCV.append(os.path.join(pathCV,dir))\n",
        "  numberOfCV[dir] = len(os.listdir(os.path.join(pathCV,dir)))\n",
        "for dir in os.listdir(pathTest):\n",
        "  images_Test_data[dir]=os.listdir(os.path.join(pathTest,dir))\n",
        "  pathOfEachtest.append(os.path.join(pathTest,dir))\n",
        "  numberOfTest[dir] = len(os.listdir(os.path.join(pathTest,dir)))\n",
        "\n",
        "def spliting(n_images,dir_name,percent=0.05):\n",
        "  count=-1\n",
        "  for i in images_train_data:\n",
        "    tmp=[] \n",
        "    tmp=images_train_data[i]\n",
        "    tmp=tmp[0:math.ceil(n_images*percent)]\n",
        "    count+=1\n",
        "    for j in tmp:\n",
        "        newpath = f'/content/breast-ultrasound-images-dataset/{dir_name}/{i}'\n",
        "        if not os.path.exists(newpath):\n",
        "               os.makedirs(newpath)\n",
        "        shutil.move(os.path.join(pathOfEachTrain[count],j),newpath)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "               \n",
        "               \n",
        "  \n",
        "   \n",
        "   \n",
        "#spliting(n_images,'cv',0.05)\n",
        "#spliting(n_images,'test',0.05)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K75hPzhSYuVt",
        "outputId": "d7e1e4c3-5fa3-4ff2-f289-f86bc9ac1f45"
      },
      "outputs": [],
      "source": [
        "n_images\n",
        "numberOfTrain\n",
        "labels=['benign','malignant','normal']\n",
        "labels\n",
        "images_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUhq0R4mRB28",
        "outputId": "b79d64ca-498c-400a-906f-3fb8a23848b9"
      },
      "outputs": [],
      "source": [
        "#data augm train\n",
        "trainGen = ImageDataGenerator(\n",
        "                             vertical_flip=True,\n",
        "                             rescale=1/255,\n",
        "                             #horizontal_flip = True\n",
        "                              )\n",
        "\n",
        "    \n",
        "z=0\n",
        "for j in images_train_data['normal']:\n",
        "    img = load_img(os.path.join(pathTrain,'normal',j))\n",
        "    x=img_to_array(img)\n",
        "    x=x.reshape((1,)+x.shape)\n",
        "    count=0\n",
        "    z+=1\n",
        "    for batch in trainGen.flow(x,save_to_dir=f\"{pathTrain}/normal\",save_prefix=f'normal_generated{z}',save_format='png'):\n",
        "        count+=1\n",
        "        if count>1:\n",
        "           break\n",
        "\n",
        "     \n",
        "Train_prepare = trainGen.flow_from_directory(directory = pathTrain,target_size=(224,224),batch_size=32,class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJaPgTKLRB-z",
        "outputId": "ac33afb7-04bf-4b68-a34b-ac9ae25837cb"
      },
      "outputs": [],
      "source": [
        "test_prepare = trainGen.flow_from_directory(directory = pathTest,target_size=(224,224),batch_size=7,class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCfU6wItRB_h",
        "outputId": "5bb87b3c-33d5-4357-a005-8aba81198fb3"
      },
      "outputs": [],
      "source": [
        "CV_prepare = trainGen.flow_from_directory(directory = pathTest,target_size=(224,224),batch_size=7,class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w2jY2VSRCAQ"
      },
      "outputs": [],
      "source": [
        "# load the InceptionResNetV2 architecture with imagenet weights as base\n",
        "base_model = tf.keras.applications.InceptionResNetV2(\n",
        "\t\t\t\t\tinclude_top=False,\n",
        "\t\t\t\t\tweights='imagenet',\n",
        "\t\t\t\t\tinput_shape=(224,224,3)\n",
        "\t\t\t\t\t)\n",
        "\n",
        "base_model.trainable=False\n",
        "# For freezing the layer we make use of layer.trainable = False\n",
        "# means that its internal state will not change during training.\n",
        "# model's trainable weights will not be updated during fit(),\n",
        "# and also its state updates will not run.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\tbase_model,\n",
        "\t\ttf.keras.layers.BatchNormalization(renorm=True),\n",
        "\t\ttf.keras.layers.GlobalAveragePooling2D(),\n",
        "\t\ttf.keras.layers.Dense(512, activation='relu'),\n",
        "\t\ttf.keras.layers.Dense(256, activation='relu'),\n",
        "\t\ttf.keras.layers.Dropout(0.5),\n",
        "\t\ttf.keras.layers.Dense(128, activation='relu'),\n",
        "\t\ttf.keras.layers.Dense(3, activation='softmax')\n",
        "\t])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KTKpWsFRCA7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMN_hFT366gq"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "es = EarlyStopping(monitor=\"val_accuracy\",min_delta=0.01,patience=3,verbose=1,mode='auto')\n",
        "mc = ModelCheckpoint(monitor=\"val_accuracy\",filepath=\"mymodel.h5\",save_best_only=True,verbose=1,mode='auto') \n",
        "cd=[es,mc] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUqVpks9RCCT",
        "outputId": "056ac4e8-e9bd-4cf3-8fac-46380b3c8a55"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(\n",
        "  Train_prepare,\n",
        "  validation_data=CV_prepare,\n",
        "  epochs=30,\n",
        "  callbacks=cd\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGv5N_crRCDC",
        "outputId": "131ac076-c64b-4960-e5ea-6a41e5e9ad36"
      },
      "outputs": [],
      "source": [
        "f=history.history\n",
        "print(f.keys())\n",
        "print(max(f['accuracy']))\n",
        "print(max(f['val_accuracy']))\n",
        "print(min(f['loss']))\n",
        "print(min(f['val_loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "penditjmvooQ",
        "outputId": "2058d11d-1c8e-48d9-cbb0-868757d05dbd"
      },
      "outputs": [],
      "source": [
        "plt.plot(f['loss'])\n",
        "plt.plot(f['val_loss'],c=\"red\")\n",
        "plt.title(\"model beh\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jzcuqtPwBbN"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/content/mymodel.h5\")\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em1Pl99TRCDt",
        "outputId": "16c3e685-eebc-4c28-a145-4cd870b4aa5e"
      },
      "outputs": [],
      "source": [
        "accuracy_score = model.evaluate(test_prepare)\n",
        "print(accuracy_score)\n",
        "print(\"Accuracy: {:.4f}%\".format(accuracy_score[1] * 100))\n",
        " \n",
        "print(\"Loss: \",accuracy_score[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "oc4asb29yHRc",
        "outputId": "fcdc23fe-ea05-4511-c20f-7610b4a734e3"
      },
      "outputs": [],
      "source": [
        "path = \"/content/A318601_1_En_3_Fig3_HTML.jpg\"\n",
        "img = load_img(path,target_size=(224,224))\n",
        "input_arr = img_to_array(img)/255\n",
        "plt.imshow(input_arr)\n",
        "plt.show()\n",
        "input_arr=np.expand_dims(input_arr,axis=0)\n",
        "pred=model.predict(input_arr)\n",
        "score =pred[0]\n",
        "print(labels[np.argmax(score)])\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(labels[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "m0GqQRGv6O7w",
        "outputId": "2abda2c0-82c1-46e0-b89b-6454f25ad11f"
      },
      "outputs": [],
      "source": [
        "path = \"/content/breast-ultrasound-images-dataset/test/benign/benign (12).png\"\n",
        "img = load_img(path,target_size=(224,224))\n",
        "input_arr = img_to_array(img)/255\n",
        "plt.imshow(input_arr)\n",
        "plt.show()\n",
        "input_arr=np.expand_dims(input_arr,axis=0)\n",
        "pred=model.predict(input_arr)\n",
        "score =pred[0]\n",
        "print(labels[np.argmax(score)])\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(labels[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "wVcqiTFiyHT4",
        "outputId": "601a4a59-3b1c-4abe-a425-ae37fee72940"
      },
      "outputs": [],
      "source": [
        "path = \"/content/breast-ultrasound-images-dataset/test/malignant/malignant (48).png\"\n",
        "img = load_img(path,target_size=(224,224))\n",
        "input_arr = img_to_array(img)/255\n",
        "plt.imshow(input_arr)\n",
        "plt.show()\n",
        "input_arr=np.expand_dims(input_arr,axis=0)\n",
        "pred=model.predict(input_arr)\n",
        "score =pred[0]\n",
        "print(labels[np.argmax(score)])\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(labels[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVOAmUSuRCGu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X6pJfQxyYWO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evrUa72xtrdi"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ae38f4dc8e962f92e933f829627eeda52c8b9ac21a54db5ece939922979b3a32"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
